4. 範例架構（升級版）
下面這個範例，是用 RandomForest+GridSearchCV+Shap explain+california_housing，給你一個起手式：

python
複製
編輯
# 1. 資料載入與前處理
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
import pandas as pd

data = fetch_california_housing()
X, y = data.data, data.target
df = pd.DataFrame(X, columns=data.feature_names)

# 2. EDA
import seaborn as sns
import matplotlib.pyplot as plt
sns.heatmap(df.corr(), annot=True)
plt.title("Feature Correlation")
plt.show()

# 3. 前處理 & 分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. 模型與參數搜尋
from sklearn.ensemble import RandomForestRegressor
param_grid = {'n_estimators':[100,200], 'max_depth':[5,10,15]}
grid = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')
grid.fit(X_train_scaled, y_train)

print("Best params:", grid.best_params_)

# 5. 評估
from sklearn.metrics import mean_squared_error, r2_score
y_pred = grid.predict(X_test_scaled)
print("MSE:", mean_squared_error(y_test, y_pred))
print("R2:", r2_score(y_test, y_pred))

# 6. Explainable AI
import shap
explainer = shap.TreeExplainer(grid.best_estimator_)
shap_values = explainer.shap_values(X_test_scaled)
shap.summary_plot(shap_values, X_test, feature_names=data.feature_names)
5. Bonus：深度學習版
python
複製
編輯
import tensorflow as tf
from tensorflow import keras
model = keras.Sequential([
    keras.layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    keras.layers.Dense(1)
])
model.compile(optimizer='adam', loss='mse', metrics=['mae'])
model.fit(X_train_scaled, y_train, epochs=20, validation_split=0.1)
6. AutoML 例子
python
複製
編輯
from tpot import TPOTRegressor
tpot = TPOTRegressor(generations=5, population_size=50, verbosity=2)
tpot.fit(X_train_scaled, y_train)
print(tpot.score(X_test_scaled, y_test))
7. 總結（寫在notebook前面或結尾）
展現你對資料科學完整流程的掌握

有模型比較、特徵工程、可解釋性

能提到 boston 棄用的原因，展現你的敏感度

甚至能對結果提出解讀與未來方向建議（如：為何 RandomForest 可能比 DecisionTree好）

